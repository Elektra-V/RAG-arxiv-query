# ============================================================================
# Company API Gateway Configuration
# ============================================================================
# Primary setup: Gateway mode with Basic auth + Qwen tooling model (FREE!)
# This matches the exact pattern from your company API documentation
# Based on: https://genai.iais.fraunhofer.de/api/v2

# ============================================================================
# REQUIRED SETTINGS - Gateway Mode (Recommended)
# ============================================================================
LLM_PROVIDER="openai"
EMBEDDING_PROVIDER="openai"  # Uses gateway (fast, no CUDA issues)
# Alternative: EMBEDDING_PROVIDER="huggingface"  # Free local embeddings (slower, CPU only)

# Gateway Authentication (Primary - FREE models with tooling support!)
OPENAI_BASE_URL="https://genai.iais.fraunhofer.de/api/v2"
OPENAI_AUTH_USERNAME="my-username"  # Your company API username
OPENAI_AUTH_PASSWORD="my-password"  # Your company API password
# OPENAI_API_KEY=""  # Leave empty - NOT needed for gateway mode!

# Model Configuration (Gateway - Free Qwen with tooling!)
OPENAI_MODEL="Qwen2.5-7B-Instruct"  # FREE Qwen model with full tooling/function calling support!
# Alternative gateway models: "Qwen2.5-VL-72B-Instruct", "Llama-3-SauerkrautLM", "gpt-4o-mini"
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"  # Embedding model from gateway

# ============================================================================
# OPTIONAL: OpenAI Platform Mode (Advanced - Paid, bears cost)
# ============================================================================
# Only use if you need OpenAI Platform directly (not recommended for most users)
# Gateway mode above is FREE and has Qwen with tooling support!
#
# # OPENAI_BASE_URL="https://api.openai.com/v1"  # Standard OpenAI Platform
# # OPENAI_API_KEY="sk-..."  # Your OpenAI Platform API key (paid)
# # OPENAI_AUTH_USERNAME=""  # Leave empty for Platform mode
# # OPENAI_AUTH_PASSWORD=""  # Leave empty for Platform mode
# # OPENAI_MODEL="gpt-4o-mini"  # Platform models: "gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"

# ============================================================================
# OPTIONAL: Per-request Headers (if your API needs them)
# ============================================================================
# These are passed as extra_headers in API calls if needed
# Format: "Header-Name:value" separated by commas
# Example from your docs: "X-Request-ID:rating-00001"
# Leave empty if not needed - the Basic auth header is handled automatically
COMPANY_API_EXTRA_HEADERS=""  # e.g., "X-Request-ID:default-id" (optional)

# ============================================================================
# QDRANT DATABASE SETTINGS
# ============================================================================
QDRANT_URL="http://localhost:6334"
QDRANT_COLLECTION="arxiv_papers"

# ============================================================================
# INGESTION SETTINGS
# ============================================================================
ARXIV_QUERY="quantum computing"
ARXIV_MAX_DOCS=5

# ============================================================================
# LANGCHAIN/LANGSMITH SETTINGS (Optional)
# ============================================================================
LANGSMITH_API_KEY=""  # Leave empty if not using LangSmith tracing
LANGSMITH_TRACING=false
LANGSMITH_PROJECT="rag-api-langchain"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"

DUCKDUCKGO_RESULTS=3

# ============================================================================
# PORT CONFIGURATION
# ============================================================================
LANGCHAIN_HOST="0.0.0.0"
LANGCHAIN_PORT=9010
LLAMAINDEX_HOST="0.0.0.0"
LLAMAINDEX_PORT=9020
INGESTION_HOST="0.0.0.0"
INGESTION_PORT=9030
