# ============================================================================
# Company API Gateway Configuration
# ============================================================================
# This matches the exact pattern from your company API documentation
# Based on: https://genai.iais.fraunhofer.de/api/v2

# ============================================================================
# REQUIRED SETTINGS
# ============================================================================
LLM_PROVIDER="openai"
EMBEDDING_PROVIDER="openai"  # Recommended: Uses company API (fast, no CUDA issues)
# Alternative: EMBEDDING_PROVIDER="huggingface"  # Free local embeddings (slower, CPU only)

# ============================================================================
# AUTHENTICATION MODE - Choose ONE:
# ============================================================================

# OPTION 1: Gateway Mode (Free models, recommended)
# Use Basic auth - no API key needed!
OPENAI_BASE_URL="https://genai.iais.fraunhofer.de/api/v2"
OPENAI_AUTH_USERNAME="my-username"  # Your company API username
OPENAI_AUTH_PASSWORD="my-password"  # Your company API password
# OPENAI_API_KEY=""  # Leave empty for gateway (not needed)

# OPTION 2: OpenAI Platform Mode (Paid, bears cost)
# Use API key - no Basic auth needed!
# OPENAI_BASE_URL="https://api.openai.com/v1"  # Standard OpenAI Platform
# OPENAI_API_KEY="sk-..."  # Your OpenAI Platform API key
# OPENAI_AUTH_USERNAME=""  # Leave empty for Platform mode
# OPENAI_AUTH_PASSWORD=""  # Leave empty for Platform mode

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
OPENAI_MODEL="Qwen2.5-7B-Instruct"  # Free Qwen model with tooling support (recommended for gateway)
# Alternative models: "Llama-3-SauerkrautLM", "gpt-4o-mini", "Qwen2.5-VL-72B-Instruct"
# For Platform mode: "gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"  # Embedding model

# ============================================================================
# OPTIONAL: Per-request Headers (if your API needs them)
# ============================================================================
# These are passed as extra_headers in API calls if needed
# Format: "Header-Name:value" separated by commas
# Example from your docs: "X-Request-ID:rating-00001"
# Leave empty if not needed - the Basic auth header is handled automatically
COMPANY_API_EXTRA_HEADERS=""  # e.g., "X-Request-ID:default-id" (optional)

# ============================================================================
# QDRANT DATABASE SETTINGS
# ============================================================================
QDRANT_URL="http://localhost:6334"
QDRANT_COLLECTION="arxiv_papers"

# ============================================================================
# INGESTION SETTINGS
# ============================================================================
ARXIV_QUERY="quantum computing"
ARXIV_MAX_DOCS=5

# ============================================================================
# LANGCHAIN/LANGSMITH SETTINGS (Optional)
# ============================================================================
LANGSMITH_API_KEY=""  # Leave empty if not using LangSmith tracing
LANGSMITH_TRACING=false
LANGSMITH_PROJECT="rag-api-langchain"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"

DUCKDUCKGO_RESULTS=3

# ============================================================================
# PORT CONFIGURATION
# ============================================================================
LANGCHAIN_HOST="0.0.0.0"
LANGCHAIN_PORT=9010
LLAMAINDEX_HOST="0.0.0.0"
LLAMAINDEX_PORT=9020
INGESTION_HOST="0.0.0.0"
INGESTION_PORT=9030
