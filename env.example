ARXIV_QUERY="quantum computing"
ARXIV_MAX_DOCS=5
QDRANT_URL="http://qdrant:6333"
QDRANT_COLLECTION="arxiv_papers"

# Model provider selection: "ollama", "openai", "anthropic"
LLM_PROVIDER="ollama"
EMBEDDING_PROVIDER="huggingface"

# OpenAI configuration (when LLM_PROVIDER="openai" or EMBEDDING_PROVIDER="openai")
OPENAI_API_KEY=""
OPENAI_MODEL="gpt-4o-mini"
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"

# Company API configuration (for custom OpenAI-compatible APIs with Basic auth)
# Example: Fraunhofer GenAI API
# OPENAI_BASE_URL="https://genai.iais.fraunhofer.de/api/v2"
# OPENAI_AUTH_USERNAME="my-username"
# OPENAI_AUTH_PASSWORD="my-password"
# OPENAI_API_KEY="xxxx"  # Can be placeholder when using Basic auth

# Anthropic configuration (when LLM_PROVIDER="anthropic")
ANTHROPIC_API_KEY=""
ANTHROPIC_MODEL="claude-3-5-sonnet-20241022"

# HuggingFace configuration (when EMBEDDING_PROVIDER="huggingface")
HUGGINGFACE_MODEL="sentence-transformers/all-MiniLM-L6-v2"

# Ollama configuration (when LLM_PROVIDER="ollama")
OLLAMA_MODEL="llama3.1:8b-instruct-q4_0"
OLLAMA_BASE_URL="http://ollama:11434"

DUCKDUCKGO_RESULTS=3

# LangSmith configuration for debugging and observability
# Get your API key from https://smith.langchain.com/
LANGSMITH_API_KEY=""
LANGSMITH_TRACING=true
LANGSMITH_PROJECT="rag-api-langchain"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"

LANGCHAIN_HOST="0.0.0.0"
LANGCHAIN_PORT=8009
LLAMAINDEX_HOST="0.0.0.0"
LLAMAINDEX_PORT=8080
INGESTION_HOST="0.0.0.0"
INGESTION_PORT=8090
OLLAMA_SOCKET=/var/run/ollama.sock
OLLAMA_MODEL_VOLUME=ollama-models