# Plug-and-Play Setup Checklist

## âœ… Verified Working Components

### Environment
- âœ… `uv` package manager installed
- âœ… Docker installed and running
- âœ… Python 3.12+ available

### Configuration
- âœ… `.env` file with OpenRouter credentials
- âœ… Model: `google/gemini-2.5-flash-preview-09-2025`
- âœ… Embeddings: HuggingFace (free, no API key needed)

### Services
- âœ… Qdrant: Running on port 6334
- âœ… Ingestion: Working (6 documents stored)
- âœ… RAG Retrieval: Functional
- âœ… LangGraph Dev: Running with `--tunnel` flag

## ğŸ“‹ For New Machine Setup

### Step 1: Clone/Copy Project
```bash
git clone <repo-url>
cd rag-api
```

### Step 2: Configure Environment
```bash
cp env.example .env
# Edit .env with your OpenRouter API key
```

### Step 3: Install Dependencies
```bash
uv sync
```

### Step 4: Start Qdrant
```bash
docker run -d -p 6334:6333 --name qdrant-local qdrant/qdrant
```

### Step 5: Ingest Documents
```bash
uv run rag-api-ingest --query "machine learning" --max-docs 5
```

### Step 6: Start Server
```bash
uv run langgraph dev --tunnel
```

### Step 7: Access Studio UI
- Copy the Studio UI URL from terminal output
- Format: `https://smith.langchain.com/studio/?baseUrl=<TUNNEL_URL>`
- Open in Safari (or any browser)

## ğŸ› Known Issues & Solutions

### Port Already in Use
- Solution: `pkill -f langgraph` then restart

### Qdrant Not Accessible
- Solution: Check if Docker is running: `docker ps`
- Restart Qdrant: `docker start qdrant-local`

### Tool Calling Errors
- Solution: Ensure model supports tool calling
- Current: `google/gemini-2.5-flash-preview-09-2025` should work
- Alternative: `openai/gpt-4o-mini` (confirmed working)

## âœ… Test Results

- âœ… Ingestion: 6 documents stored
- âœ… Retrieval: Working (found relevant results)
- âœ… Server: Running with tunnel
- âœ… Configuration: All settings verified

